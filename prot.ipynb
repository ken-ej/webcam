{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "/Users/ken/Documents/ano_dev/anomalib/.venv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                     </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model                 │ PatchcoreModel           │ 24.9 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _transform            │ Compose                  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ normalization_metrics │ MetricCollection         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ image_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ pixel_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ image_metrics         │ AnomalibMetricCollection │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ pixel_metrics         │ AnomalibMetricCollection │      0 │ train │\n",
       "└───┴───────────────────────┴──────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model                 │ PatchcoreModel           │ 24.9 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _transform            │ Compose                  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ normalization_metrics │ MetricCollection         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ image_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ pixel_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ image_metrics         │ AnomalibMetricCollection │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ pixel_metrics         │ AnomalibMetricCollection │      0 │ train │\n",
       "└───┴───────────────────────┴──────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 24.9 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 24.9 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 99                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 24.9 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 24.9 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 99                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/Documents/ano_dev/anomalib/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/ken/Documents/ano_dev/anomalib/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8fad5ff62c45f1943800037dede2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/ken/Documents/ano_dev/anomalib/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/autom\n",
       "atic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/ken/Documents/ano_dev/anomalib/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/autom\n",
       "atic.py:132: `training_step` returned `None`. If this was on purpose, ignore this warning...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02e96f9fd15442c90e495f19910bad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "/Users/ken/Documents/ano_dev/anomalib/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:419: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c9d778d42846a4935d47e529272177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'image_AUROC': 1.0, 'image_F1Score': 0.0}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##patchcore学習完成###\n",
    "\n",
    "import torch\n",
    "from anomalib.data import Folder\n",
    "from anomalib.models import Patchcore\n",
    "#from anomalib.trainers import Trainer\n",
    "from anomalib import TaskType\n",
    "from anomalib.engine import Engine\n",
    "\n",
    "# MPS（Apple GPU）を使用する設定\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# データセットのパス設定\n",
    "DATASET_PATH = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample3/\"\n",
    "OUTPUT_PATH = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample3/\"\n",
    "\n",
    "# データモジュールの設定\n",
    "datamodule = Folder(\n",
    "    name=\"my_sample\",\n",
    "    root=\"datasets/my_sample3\",\n",
    "    normal_dir=\"train/good\",\n",
    "    abnormal_dir=\"test/ng\",\n",
    "    #mask_dir=\"ground_truth\",\n",
    "    normal_test_dir=\"test/good\",\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=32,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    "    #task=TaskType.SEGMENTATION,\n",
    "    #root=DATASET_PATH,\n",
    "    #normal_dir=\"train/OK\",\n",
    "    #abnormal_dir=\"train/NG\",\n",
    "    image_size=(128, 128),  # 必要に応じて変更\n",
    ")\n",
    "datamodule.setup()\n",
    "\n",
    "# PatchCoreモデルの設定\n",
    "model = Patchcore(\n",
    "    backbone=\"wide_resnet50_2\",\n",
    "    layers=(\"layer2\", \"layer3\"),\n",
    "    pre_trained=True,\n",
    "    #backbone=\"mobilenetv3_large_100\",  # 使用するバックボーンを指定\n",
    "    #layers=(\"blocks.1\",\"blocks.2\",\"blocks.4\",\"blocks.6\"), # MobileNetV3の適切なレイヤーを指定\n",
    "    #pre_trained=True,\n",
    "    coreset_sampling_ratio=0.1,\n",
    "    num_neighbors = 9\n",
    "    #input_size=(256, 256),  # 必要に応じて変更\n",
    "    #backbone=\"resnet18\",    # 適切なバックボーンを選択\n",
    "    #pre_trained=True,       # 事前学習済みモデルを使用\n",
    ").to(device)  # モデルをMPSに転送\n",
    "\n",
    "# トレーナーの設定\n",
    "engine = Engine(\n",
    "    max_epochs=50,  # エポック数を設定\n",
    "    accelerator=\"auto\",  # 自動的に適切なハードウェアを選択（MPSが優先される）\n",
    "    devices=1,  # デバイス数を指定\n",
    "    default_root_dir=OUTPUT_PATH,  # 出力フォルダ\n",
    ")\n",
    "\n",
    "# 学習実行\n",
    "engine.fit(model, datamodule)\n",
    "engine.test(datamodule=datamodule, model=model, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##patchcore学習完成###\n",
    "\n",
    "import torch\n",
    "from anomalib.data import Folder\n",
    "from anomalib.models import Patchcore\n",
    "from anomalib import TaskType\n",
    "from anomalib.engine import Engine\n",
    "\n",
    "# MPS（Apple GPU）を使用する設定\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# データセットのパス設定\n",
    "DATASET_PATH = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample3/\"\n",
    "OUTPUT_PATH = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample3/\"\n",
    "\n",
    "# データモジュールの設定\n",
    "datamodule = Folder(\n",
    "    name=\"my_sample\",\n",
    "    root=\"datasets/my_sample3\",\n",
    "    normal_dir=\"train/good\",\n",
    "    abnormal_dir=\"test/ng\",\n",
    "    #mask_dir=\"ground_truth\",\n",
    "    normal_test_dir=\"test/good\",\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=32,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    "    #task=TaskType.SEGMENTATION,\n",
    "    #root=DATASET_PATH,\n",
    "    #normal_dir=\"train/OK\",\n",
    "    #abnormal_dir=\"train/NG\",\n",
    "    image_size=(128, 128),  # 必要に応じて変更\n",
    ")\n",
    "datamodule.setup()\n",
    "\n",
    "# PatchCoreモデルの設定\n",
    "model = Patchcore(\n",
    "    backbone=\"wide_resnet50_2\",\n",
    "    layers=(\"layer2\", \"layer3\"),\n",
    "    pre_trained=True,\n",
    "    coreset_sampling_ratio=0.1,\n",
    "    num_neighbors = 9\n",
    ").to(device)  # モデルをMPSに転送\n",
    "\n",
    "# トレーナーの設定\n",
    "engine = Engine(\n",
    "    #max_epochs=50,  # エポック数を設定\n",
    "    #accelerator=\"auto\",  # 自動的に適切なハードウェアを選択（MPSが優先される）\n",
    "    #devices=1,  # デバイス数を指定\n",
    "    default_root_dir=OUTPUT_PATH,  # 出力フォルダ\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "Restoring states from the checkpoint path at /Users/ken/Documents/ano_dev/anomalib/datasets/my_sample3/Patchcore/my_sample/v5/weights/lightning/model.ckpt\n",
      "Loaded model weights from the checkpoint at /Users/ken/Documents/ano_dev/anomalib/datasets/my_sample3/Patchcore/my_sample/v5/weights/lightning/model.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9016aeb2c89c45158df2b84e5f2dd8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/Documents/ano_dev/anomalib/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.514562\n",
      "Name: pred_scores, dtype: float64\n",
      "0    68.503387\n",
      "Name: org_anomaly_score, dtype: float64\n",
      "Columns in df: Index(['Unnamed: 0', 'image_path', 'pred_scores', 'org_anomaly_score'], dtype='object')\n",
      "Image 0: ['/Users/ken/Documents/ano_dev/anomalib/captured_images/captured_image.jpg']\n",
      "  Pred Score: 0.5145623087882996\n",
      "  Org Anomaly Score: 68.50338745117188\n",
      "  Result: NG\n",
      "--------------------\n",
      "Processed results saved to ./results/processed_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jsonargparse import Namespace\n",
    "from anomalib.models import Patchcore\n",
    "from anomalib.data import Folder\n",
    "from anomalib import TaskType\n",
    "\n",
    "\n",
    "predictions = engine.predict(\n",
    "    model=model,\n",
    "    ckpt_path = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample3/Patchcore/my_sample/v5/weights/lightning/model.ckpt\",\n",
    "    data_path = \"/Users/ken/Documents/ano_dev/anomalib/captured_images/\",\n",
    "    return_predictions=True\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(predictions)\n",
    "#print(df.columns)\n",
    "\n",
    "#異常度\n",
    "df[\"pred_scores\"] = df[\"pred_scores\"].apply(lambda x:x[0].item())\n",
    "print(df[\"pred_scores\"])\n",
    "#############################\n",
    "#規格前のknnの距離\n",
    "df[\"org_anomaly_score\"] = df[\"org_anomaly_score\"].apply(lambda x:x.item())\n",
    "print(df[\"org_anomaly_score\"])\n",
    "#############################\n",
    "#異常度マップをnumpy arrayに変換\n",
    "df[\"anomaly_maps\"] = df[\"anomaly_maps\"].apply(lambda x: np.array([[[b.item() for b in a] for a in z] for z in y] for y in x).squeeze())\n",
    "\n",
    "save_df = df.loc[:,(\"image_path\",\"pred_scores\",\"org_anomaly_score\")]\n",
    "\n",
    "df[\"pred_scores\"].plot.hist()\n",
    "plt.savefig('/Users/ken/Documents/ano_dev/anomalib/.results/' + \"/fig.png\")\n",
    "save_df.to_csv('/Users/ken/Documents/ano_dev/anomalib/.results/' + \"/results.csv\")\n",
    "\n",
    "\n",
    "output_dir = \"./results\"  # 出力フォルダのパス\n",
    "threshold = 0.5  # 閾値\n",
    "\n",
    "# 結果CSVを読み込む\n",
    "#results_csv = f\"{output_dir}/results.csv\"\n",
    "results_csv = '/Users/ken/Documents/ano_dev/anomalib/.results/results.csv'\n",
    "df = pd.read_csv(results_csv)\n",
    "\n",
    "# 列名を確認\n",
    "print(f\"Columns in df: {df.columns}\")\n",
    "\n",
    "# 必要な列だけ取り出し、リスト化\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        image_path = row[\"image_path\"]\n",
    "        pred_score = row[\"pred_scores\"]\n",
    "        org_anomaly_score = row[\"org_anomaly_score\"]\n",
    "        result = \"NG\" if pred_score > threshold else \"OK\"\n",
    "\n",
    "        # 結果を辞書形式で格納\n",
    "        results.append({\n",
    "            \"Image Path\": image_path,\n",
    "            \"Pred Score\": pred_score,\n",
    "            \"Org Anomaly Score\": org_anomaly_score,\n",
    "            \"Result\": result\n",
    "        })\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column in row: {e}\")\n",
    "\n",
    "# 結果を表示\n",
    "for idx, res in enumerate(results, start=0):\n",
    "    print(f\"Image {idx}: {res['Image Path']}\")\n",
    "    print(f\"  Pred Score: {res['Pred Score']}\")\n",
    "    print(f\"  Org Anomaly Score: {res['Org Anomaly Score']}\")\n",
    "    print(f\"  Result: {res['Result']}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# 結果をCSVファイルに保存\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f\"{output_dir}/processed_results.csv\", index=False)\n",
    "print(f\"Processed results saved to {output_dir}/processed_results.csv\")\n",
    "\n",
    "# 変数データのクリア\n",
    "del df, results, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#推論コマンドをAPIで実行。約2秒で処理できるのでこちらをベースに開発する\n",
    "#初版ver1.0\n",
    "\n",
    "from jsonargparse import Namespace\n",
    "from tools.inference.my_lightning_inference import infer\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = \"./results\"  # 出力フォルダのパス\n",
    "threshold = 0.5  # 閾値\n",
    "\n",
    "# 引数を設定\n",
    "args = Namespace(\n",
    "    ckpt_path=\"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/Patchcore/my_sample/v25/weights/lightning/model.ckpt\",\n",
    "    data={\"path\": \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/target1/\"},\n",
    "    output=\"/Users/ken/Documents/ano_dev/anomalib/results\",\n",
    "    #model=\"Patchcore\",\n",
    "    #    backbone=\"mobilenetv3_large_100\",  # 使用するバックボーンを指定\n",
    "    #layers=(\"blocks.1\",\"blocks.2\",\"blocks.4\",\"blocks.6\"), # MobileNetV3の適切なレイヤーを指定\n",
    "    model = Patchcore(backbone=\"mobilenetv3_large_100\", layers=[\"blocks.1\", \"blocks.2\", \"blocks.4\", \"blocks.6\"]),\n",
    "    threshold = 0.5,  # 閾値\n",
    "    callbacks=None,\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "# 推論を実行\n",
    "infer(args)\n",
    "\n",
    "\n",
    "# 結果CSVを読み込む\n",
    "results_csv = f\"{output_dir}/results.csv\"\n",
    "df = pd.read_csv(results_csv)\n",
    "\n",
    "# 必要な列だけ取り出し、リスト化\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    image_path = row[\"image_path\"]\n",
    "    pred_score = row[\"pred_scores\"]\n",
    "    org_anomaly_score = row[\"org_anomaly_score\"]\n",
    "    result = \"NG\" if pred_score > threshold else \"OK\"\n",
    "\n",
    "    # 結果を辞書形式で格納\n",
    "    results.append({\n",
    "        \"Image Path\": image_path,\n",
    "        \"Pred Score\": pred_score,\n",
    "        \"Org Anomaly Score\": org_anomaly_score,\n",
    "        \"Result\": result\n",
    "    })\n",
    "\n",
    "# 結果を表示\n",
    "for idx, res in enumerate(results, start=1):\n",
    "    print(f\"Image {idx}: {res['Image Path']}\")\n",
    "    print(f\"  Pred Score: {res['Pred Score']}\")\n",
    "    print(f\"  Org Anomaly Score: {res['Org Anomaly Score']}\")\n",
    "    print(f\"  Result: {res['Result']}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# 結果をCSVファイルに保存\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f\"{output_dir}/processed_results.csv\", index=False)\n",
    "print(f\"Processed results saved to {output_dir}/processed_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#推論コマンドをAPIで実行。約2秒で処理できるのでこちらをベースに開発する\n",
    "#OKNGのみ結果をリターン検討\n",
    "#行けそう。開発ベースはこれ ver1.1\n",
    "\n",
    "import time  # 時間計測のためのモジュール\n",
    "from jsonargparse import Namespace\n",
    "from tools.inference.my_lightning_inference import infer\n",
    "import pandas as pd\n",
    "\n",
    "def run_inference():\n",
    "    output_dir = \"./results\"  # 出力フォルダのパス\n",
    "    threshold = 0.9  # 閾値\n",
    "\n",
    "    # 処理の開始時間を記録\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 引数を設定\n",
    "    args = Namespace(\n",
    "        ckpt_path=\"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/Patchcore/my_sample/v16/weights/lightning/model.ckpt\",\n",
    "        data={\"path\": \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/target1/\"},\n",
    "        output=\"/Users/ken/Documents/ano_dev/anomalib/results\",\n",
    "        model=\"Patchcore\",\n",
    "        threshold=0.9,  # 閾値\n",
    "        callbacks=None,\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "    # 推論を実行\n",
    "    infer(args)\n",
    "\n",
    "    # 結果CSVを読み込む\n",
    "    results_csv = f\"{output_dir}/results.csv\"\n",
    "    df = pd.read_csv(results_csv)\n",
    "\n",
    "    # 結果を取得（最初の画像のみ）\n",
    "    row = df.iloc[0]  # 最初の画像の結果を使用\n",
    "    pred_score = row[\"pred_scores\"]\n",
    "\n",
    "    # OK/NG を決定\n",
    "    result = \"NG\" if pred_score > threshold else \"OK\"\n",
    "\n",
    "    # 処理の終了時間を記録\n",
    "    end_time = time.time()\n",
    "\n",
    "    # 処理時間を計算\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Processing time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "def main():\n",
    "    # スクリプト実行設定\n",
    "    inference_script = \"tools/inference/my_lightning_inference.py\"  # lightning_inference.pyのパス\n",
    "    checkpoint_path = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/Patchcore/my_sample/v16/weights/lightning/model.ckpt\"  # チェックポイントファイルのパス\n",
    "    data_path = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/target/\"  # データフォルダのパス\n",
    "    output_dir = \"./results\"  # 出力フォルダのパス\n",
    "    threshold = 0.5  # 閾値\n",
    "\n",
    "    # lightning_inference.pyを実行\n",
    "    cmd = [\n",
    "        \"python\",\n",
    "        inference_script,\n",
    "        \"--ckpt_path\", checkpoint_path,\n",
    "        \"--data.path\", data_path,\n",
    "        \"--output\", output_dir,\n",
    "        \"--model\", \"Patchcore\",\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    # 結果CSVを読み込む\n",
    "    results_csv = f\"{output_dir}/results.csv\"\n",
    "    df = pd.read_csv(results_csv)\n",
    "\n",
    "    # 分岐処理\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[\"image_path\"]\n",
    "        pred_score = row[\"pred_scores\"]\n",
    "        org_anomaly_score = row[\"org_anomaly_score\"]\n",
    "\n",
    "        print(f\"Image: {image_path}\")\n",
    "        print(f\"Pred Score: {pred_score}, Org Anomaly Score: {org_anomaly_score}\")\n",
    "\n",
    "        if pred_score > threshold:\n",
    "            print(f\"Result: NG (Anomaly detected for {image_path})\")\n",
    "        else:\n",
    "            print(f\"Result: OK (No significant anomaly for {image_path})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"推論 CSVから読み込み\"\"\"\n",
    "#コマンド起動のため遅いから没\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "def main():\n",
    "    # スクリプト実行設定\n",
    "    inference_script = \"tools/inference/my_lightning_inference.py\"  # lightning_inference.pyのパス\n",
    "    checkpoint_path = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/Patchcore/my_sample/v16/weights/lightning/model.ckpt\"  # チェックポイントファイルのパス\n",
    "    data_path = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/target1/\"  # データフォルダのパス\n",
    "    output_dir = \"./results\"  # 出力フォルダのパス\n",
    "    threshold = 0.9  # 閾値\n",
    "\n",
    "    # lightning_inference.pyを実行\n",
    "    cmd = [\n",
    "        \"python\",\n",
    "        inference_script,\n",
    "        \"--ckpt_path\", checkpoint_path,\n",
    "        \"--data.path\", data_path,\n",
    "        \"--output\", output_dir,\n",
    "        \"--model\", \"Patchcore\",\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    # 結果CSVを読み込む\n",
    "    results_csv = f\"{output_dir}/results.csv\"\n",
    "    df = pd.read_csv(results_csv)\n",
    "\n",
    "    # 必要な列だけ取り出し、リスト化\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[\"image_path\"]\n",
    "        pred_score = row[\"pred_scores\"]\n",
    "        org_anomaly_score = row[\"org_anomaly_score\"]\n",
    "        result = \"NG\" if pred_score > threshold else \"OK\"\n",
    "\n",
    "        # 結果を辞書形式で格納\n",
    "        results.append({\n",
    "            \"Image Path\": image_path,\n",
    "            \"Pred Score\": pred_score,\n",
    "            \"Org Anomaly Score\": org_anomaly_score,\n",
    "            \"Result\": result\n",
    "        })\n",
    "\n",
    "    # 結果を表示\n",
    "    for idx, res in enumerate(results, start=1):\n",
    "        print(f\"Image {idx}: {res['Image Path']}\")\n",
    "        print(f\"  Pred Score: {res['Pred Score']}\")\n",
    "        print(f\"  Org Anomaly Score: {res['Org Anomaly Score']}\")\n",
    "        print(f\"  Result: {res['Result']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    # 結果をCSVファイルに保存\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f\"{output_dir}/processed_results.csv\", index=False)\n",
    "    print(f\"Processed results saved to {output_dir}/processed_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"推論 メモリーから読み込み\"\"\"\n",
    "#コマンド起動のため遅いから没\n",
    "\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import io\n",
    "import re\n",
    "\n",
    "def main():\n",
    "    # スクリプト実行設定\n",
    "    inference_script = \"tools/inference/my2_lightning_inference.py\"  # lightning_inference.pyのパス\n",
    "    checkpoint_path = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/Patchcore/my_sample/v16/weights/lightning/model.ckpt\"  # チェックポイントファイルのパス\n",
    "    data_path = \"/Users/ken/Documents/ano_dev/anomalib/datasets/my_sample/target1/\"  # データフォルダのパス\n",
    "    output_dir = \"./results\"  # 出力フォルダのパス\n",
    "    threshold = 0.9  # 閾値\n",
    "\n",
    "    # lightning_inference.pyを実行\n",
    "    cmd = [\n",
    "        \"python\",\n",
    "        inference_script,\n",
    "        \"--ckpt_path\", checkpoint_path,\n",
    "        \"--data.path\", data_path,\n",
    "        \"--output\", output_dir,\n",
    "        \"--model\", \"Patchcore\",\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # 標準出力とエラーをキャプチャ\n",
    "        result = subprocess.run(cmd, check=True, text=True, capture_output=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Subprocess failed with error: {e.stderr}\")\n",
    "        return\n",
    "\n",
    "    # 標準出力から結果を抽出\n",
    "    raw_output = result.stdout\n",
    "    print(\"Raw output:\\n\", raw_output)  # デバッグ用に出力を表示\n",
    "\n",
    "    # エスケープシーケンスを保持しつつ、CSV部分を抽出\n",
    "    csv_pattern = r\"(image_path,pred_scores,org_anomaly_score\\n.+)\"\n",
    "    match = re.search(csv_pattern, raw_output, re.DOTALL)\n",
    "    if not match:\n",
    "        print(\"CSV data not found in the output.\")\n",
    "        return\n",
    "\n",
    "    csv_data = match.group(1)\n",
    "\n",
    "    # DataFrameに変換\n",
    "    try:\n",
    "        df = pd.read_csv(io.StringIO(csv_data))\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"CSV parsing error: {e}\")\n",
    "        print(\"CSV data was:\\n\", csv_data)\n",
    "        return\n",
    "\n",
    "    print(\"Parsed DataFrame columns:\", df.columns)\n",
    "\n",
    "    # 必要な列だけ取り出し、リスト化\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = row[\"image_path\"]\n",
    "        pred_score = float(row[\"pred_scores\"])\n",
    "        org_anomaly_score = float(row[\"org_anomaly_score\"])\n",
    "        result = \"NG\" if pred_score > threshold else \"OK\"\n",
    "\n",
    "        # 結果を辞書形式で格納\n",
    "        results.append({\n",
    "            \"Image Path\": image_path,\n",
    "            \"Pred Score\": pred_score,\n",
    "            \"Org Anomaly Score\": org_anomaly_score,\n",
    "            \"Result\": result\n",
    "        })\n",
    "\n",
    "    # 結果を表示\n",
    "    for idx, res in enumerate(results, start=1):\n",
    "        print(f\"Image {idx}: {res['Image Path']}\")\n",
    "        print(f\"  Pred Score: {res['Pred Score']}\")\n",
    "        print(f\"  Org Anomaly Score: {res['Org Anomaly Score']}\")\n",
    "        print(f\"  Result: {res['Result']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    # 結果をCSVファイルに保存\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f\"{output_dir}/processed_results.csv\", index=False)\n",
    "    print(f\"Processed results saved to {output_dir}/processed_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
