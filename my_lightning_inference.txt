"""Inference Entrypoint script."""
###異常値出力対応####


# Copyright (C) 2022-2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

from jsonargparse import ActionConfigFile, Namespace
from lightning.pytorch.callbacks import Callback
from lightning.pytorch.cli import LightningArgumentParser
from torch.utils.data import DataLoader

from anomalib.data import PredictDataset
from anomalib.engine import Engine
from anomalib.models import AnomalyModule, get_model





def get_parser() -> LightningArgumentParser:
    """Get parser.

    Returns:
        LightningArgumentParser: The parser object.
    """
    parser = LightningArgumentParser(description="Inference on Anomaly models in Lightning format.")
    parser.add_lightning_class_args(AnomalyModule, "model", subclass_mode=True)
    parser.add_lightning_class_args(Callback, "--callbacks", subclass_mode=True, required=False)
    parser.add_argument("--ckpt_path", type=str, required=True, help="Path to model weights")
    parser.add_class_arguments(PredictDataset, "--data", instantiate=False)
    parser.add_argument("--output", type=str, required=False, help="Path to save the output image(s).")
    parser.add_argument(
        "--show",
        action="store_true",
        required=False,
        help="Show the visualized predictions on the screen.",
    )
    parser.add_argument(
        "-c",
        "--config",
        action=ActionConfigFile,
        help="Path to a configuration file in json or yaml format.",
    )

    return parser


def infer(args: Namespace) -> None:
    """Run inference."""
    callbacks = None if not hasattr(args, "callbacks") else args.callbacks
    engine = Engine(
        default_root_dir=args.output,
        callbacks=callbacks,
        devices=1,
    )
    model = get_model(args.model)

    # create the dataset
    dataset = PredictDataset(**args.data)
    dataloader = DataLoader(dataset)

    # replace and add here
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt

    results =  engine.predict(model=model, dataloaders=[dataloader], ckpt_path=args.ckpt_path)

    df = pd.DataFrame(results)
    #print(df.columns)

    """②スプリクト実行の使い方
        lightningのチェックポイントファイルを指定する方法
        python .¥tools¥inference¥my_lightning_inference.py --ckpt_path path/to/checkpoint.ckpt --data.path path/to/data --output ./prediction_results --model Patchcore
        このスクリプトと使えば任意の結果の出力が可能です。
        例
        異常値の分布をプロットする
        異常値の結果をCSV出力する
        規格化前のknnの距離を出力する
    
    """
    #############################
    #異常度
    df["pred_scores"] = df["pred_scores"].apply(lambda x:x[0].item())
    #############################
    #規格前のknnの距離
    df["org_anomaly_score"] = df["org_anomaly_score"].apply(lambda x:x.item())
    #############################
    #異常度マップをnumpy arrayに変換
    df["anomaly_maps"] = df["anomaly_maps"].apply(lambda x: np.array([[[b.item() for b in a] for a in z] for z in y] for y in x).squeeze())

    save_df = df.loc[:,("image_path","pred_scores","org_anomaly_score")]

    df["pred_scores"].plot.hist()
    plt.savefig(args.output + "/fig.png")
    save_df.to_csv(args.output + "/results.csv")

if __name__ == "__main__":
    parser = get_parser()
    args = parser.parse_args()
    infer(args)
